{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* AWS region.\n",
    "* IAM role 에 필요한 권한을 추가해야 합니다.\n",
    "** Rekognition, Textract API and S3 bucket.\n",
    "\n",
    "* 테스트 환경 : SageMeker - Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefix = \"sagemaker/pii-detection-redaction\"\n",
    "bucket_path = \"https://s3-{}.amazonaws.com/{}\".format(region, bucket)\n",
    "# Customize to your bucket where you have stored the data\n",
    "print(bucket_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textract\n",
    "\n",
    "Amazon Textract는 스캔한 문서에서 텍스트, 필기 및 데이터를 자동으로 추출하는 기계 학습(ML) 서비스입니다. 단순한 광학 문자 인식(OCR) 이상으로 양식 및 표의 데이터를 식별하고 이해하며 추출합니다.\n",
    "\n",
    "* [Amazon Textract Code Samples](https://github.com/aws-samples/amazon-textract-code-samples)\n",
    "* [python-textract-textract_wrapper.py](https://docs.aws.amazon.com/ko_kr/code-samples/latest/catalog/python-textract-textract_wrapper.py.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "object='sagemaker/pii-detection-redaction/sample1.jpg'\n",
    "\n",
    "# Amazon Textract client\n",
    "textract = boto3.client('textract')\n",
    "\n",
    "# Call Amazon Textract\n",
    "response = textract.detect_document_text(\n",
    "    Document={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket,\n",
    "            'Name': object\n",
    "        }\n",
    "    })\n",
    "\n",
    "#print(response)\n",
    "\n",
    "# Print detected text\n",
    "for item in response[\"Blocks\"]:\n",
    "    if item[\"BlockType\"] == \"LINE\":\n",
    "        print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Rekognition\n",
    "\n",
    "Amazon Rekognition은 이미지 및 비디오에서 정보와 인사이트를 추출하기 위해 사전 훈련된 컴퓨터 비전(CV) 및 사용자 지정 가능한 CV 기능을 제공합니다. Amazon Rekognition - DetectLabels 작업을 사용하여 이미지에서 레이블을 감지할 수 있습니다.\n",
    "[이미지에서 레이블 감지](https://docs.aws.amazon.com/ko_kr/rekognition/latest/dg/labels-detect-labels-image.html)\n",
    "\n",
    "DetectText는 이미지에서 최대 100개 단어를 감지할 수 있습니다. 이미지에서 추가로 감지 할 수 있는지는 티켓으로 문의해봐야 합니다.\n",
    "[Amazon Rekognition 텍스트 감지 기능 향상 발표](https://aws.amazon.com/ko/about-aws/whats-new/2021/05/enhancements-to-amazon-rekognition-text-detection-support-for-more-words-higher-accuracy-lower-latency/)\n",
    "\n",
    "양식이 정해져 있고 주민번호가 문서의 하단에 있기 때문에, 이미지를 거꾸로 회전하여 검색하시면 100자 이내에 주민번호 검색이 가능했습니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "object='sagemaker/pii-detection-redaction/sample2.jpg'\n",
    "\n",
    "redacted_box_color='red'\n",
    "dpi = 72\n",
    "pii_detection_threshold = 0.00\n",
    "\n",
    "\n",
    "# If the image is in DICOM format, convert it to PNG\n",
    "if (object.split(\".\")[-1:][0] == \"dcm\"):\n",
    "    ! aws s3 cp s3://{bucket}/{object} .\n",
    "    ! convert -format png {object.split(\"/\")[-1:][0]} {object.split(\"/\")[-1:][0]}.png\n",
    "    ! aws s3 cp {object.split(\"/\")[-1:][0]}.png s3://{bucket}/{object}.png\n",
    "    object=object+'.png'\n",
    "    print(object)\n",
    "\n",
    "# Import all of the required libraries\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from imageio import imread\n",
    "\n",
    "import base64\n",
    "# Import cStringIO0\n",
    "\n",
    "\n",
    "\n",
    "# Implement AWS Services\n",
    "rekognition=boto3.client('rekognition')\n",
    "comprehend = boto3.client(service_name='comprehend')\n",
    "s3=boto3.resource('s3')\n",
    "\n",
    "# Download the image from S3 and hold it in memory\n",
    "img_bucket = s3.Bucket(bucket)\n",
    "img_object = img_bucket.Object(object)\n",
    "xray = io.BytesIO()\n",
    "img_object.download_fileobj(xray)\n",
    "img = np.array(Image.open(xray), dtype=np.uint8)\n",
    "print(img.shape)\n",
    "# Set the image color map to grayscale, turn off axis grapiing, and display the image\n",
    "height, width,channel = img.shape\n",
    "# What size does the figure need to be in inches to fit the image?\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "# Create a figure of the right size with one axes that takes up the full figure\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "# Hide spines, ticks, etc.\n",
    "ax.axis('off')\n",
    "# Display the image.\n",
    "ax.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 검색된 이미지 라벨에서 '숫자 6자리 - 숫자 7자리' 형식으로 검색된 글자를 주민번호라 가정하였습니다.\n",
    "import re\n",
    "regex = re.compile(r'\\d{6}-\\d{7}')\n",
    "\n",
    "# Use Amazon Rekognition to detect all of the text in the image\n",
    "response=rekognition.detect_text(Image={'Bytes':xray.getvalue()})\n",
    "textDetections=response['TextDetections']\n",
    "print ('Aggregating detected text...')\n",
    "textblock=\"\"\n",
    "offsetarray=[]\n",
    "totallength=0\n",
    "\n",
    "for text in textDetections:\n",
    "    if text['Type'] == \"LINE\":\n",
    "        match = regex.search(text['DetectedText'])\n",
    "        if bool(match) == True:\n",
    "            offsetarray.append(text)\n",
    "            totallength+=len(text['DetectedText'])+1\n",
    "            textblock=textblock+text['DetectedText']+\" \"  \n",
    "\n",
    "totaloffsets=len(offsetarray)\n",
    "print(offsetarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now this list of bounding boxes will be used to draw red boxes over the pii text.\n",
    "height, width, channel = img.shape\n",
    "# What size does the figure need to be in inches to fit the image?\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "# Create a figure of the right size with one axes that takes up the full figure\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.imshow(img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "# for box in pii_boxes_list:\n",
    "for box in offsetarray:\n",
    "    #The bounding boxes are described as a ratio of the overall image dimensions, so we must multiply them\n",
    "    #by the total image dimensions to get the exact pixel values for each dimension.\n",
    "    x = img.shape[1] * box['Geometry']['BoundingBox']['Left']\n",
    "    y = img.shape[0] * box['Geometry']['BoundingBox']['Top']\n",
    "    width = img.shape[1] * box['Geometry']['BoundingBox']['Width']\n",
    "    height = img.shape[0] * box['Geometry']['BoundingBox']['Height']\n",
    "    rect = patches.Rectangle((x,y),width,height,linewidth=0,edgecolor=redacted_box_color,facecolor=redacted_box_color)\n",
    "    ax.add_patch(rect)\n",
    "# Ensure that no axis or whitespaces is printed in the image file we want to save.\n",
    "plt.axis('off')    \n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "# Save redacted   image to the same Amazon S3 bucket, in PNG format, with 'de-id-' in front of the original filename.\n",
    "img_data = io.BytesIO()\n",
    "plt.savefig(img_data, bbox_inches='tight', pad_inches=0, format='png')\n",
    "img_data.seek(0)\n",
    "# Write the redacted image to S3\n",
    "#object='sagemaker/pii-detection-redaction/wa-license.png'\n",
    "img_bucket.put_object(Body=img_data, ContentType='image/png', Key=\"redacted/\"+object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오픈소스 EasyOCR \n",
    "\n",
    "한글뿐만 아니라 다양한 언어를 지원하고 있고, Demo website에서 테스트 해보니 한글 인식이 잘되서 테스트 했습니다.\n",
    "\n",
    "* [github](https://github.com/JaidedAI/EasyOCR)\n",
    "* [document](https://www.jaided.ai/easyocr/documentation/)\n",
    "\n",
    "패키지 설치후 \"ImportError: cannot import name _registerMatType\" 오류가 발생하는 경우 버전을 내려서 맞춰주시면 됩니다.\n",
    "참고로, gpu 옵션도 사용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "object='sagemaker/pii-detection-redaction/sample1.jpg'\n",
    "\n",
    "redacted_box_color='red'\n",
    "dpi = 72\n",
    "pii_detection_threshold = 0.00\n",
    "\n",
    "\n",
    "# If the image is in DICOM format, convert it to PNG\n",
    "if (object.split(\".\")[-1:][0] == \"dcm\"):\n",
    "    ! aws s3 cp s3://{bucket}/{object} .\n",
    "    ! convert -format png {object.split(\"/\")[-1:][0]} {object.split(\"/\")[-1:][0]}.png\n",
    "    ! aws s3 cp {object.split(\"/\")[-1:][0]}.png s3://{bucket}/{object}.png\n",
    "    object=object+'.png'\n",
    "    print(object)\n",
    "\n",
    "# Import all of the required libraries\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from imageio import imread\n",
    "\n",
    "import base64\n",
    "# Import cStringIO\n",
    "\n",
    "\n",
    "\n",
    "# Implement AWS Services\n",
    "rekognition=boto3.client('rekognition')\n",
    "comprehend = boto3.client(service_name='comprehend')\n",
    "s3=boto3.resource('s3')\n",
    "\n",
    "# Download the image from S3 and hold it in memory\n",
    "img_bucket = s3.Bucket(bucket)\n",
    "img_object = img_bucket.Object(object)\n",
    "xray = io.BytesIO()\n",
    "img_object.download_fileobj(xray)\n",
    "img = np.array(Image.open(xray), dtype=np.uint8)\n",
    "print(img.shape)\n",
    "# Set the image color map to grayscale, turn off axis grapiing, and display the image\n",
    "height, width,channel = img.shape\n",
    "# What size does the figure need to be in inches to fit the image?\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "# Create a figure of the right size with one axes that takes up the full figure\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "# Hide spines, ticks, etc.\n",
    "ax.axis('off')\n",
    "# Display the image.\n",
    "ax.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ImportError: cannot import name '_registerMatType'\n",
    "#주의 : 위 오류 발생시에만 작업하세요!!!\n",
    "!pip install \"opencv-python-headless<4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this needs to run only once to load the model into memory\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['ko'])\n",
    "# reader = easyocr.Reader(['ko', 'en'], gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파일을 직접 읽을때 사용합니다\n",
    "# textDetections = reader.readtext('sample1.jpg')\n",
    "\n",
    "# 위에서 S3 데이터를 설정하였습니다\n",
    "textDetections = reader.readtext(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r'.*\\d{6}-\\d{7}')\n",
    "\n",
    "print ('Aggregating detected text...')\n",
    "textblock=\"\"\n",
    "offsetarray=[]\n",
    "\n",
    "for text in textDetections:\n",
    "    match = regex.search(text[1])\n",
    "    if bool(match) == True:\n",
    "        offsetarray.append(text)\n",
    "        textblock=textblock+text[1]+\" \"  \n",
    "\n",
    "print(offsetarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This list of bounding boxes will be used to draw red boxes over the PII text.\n",
    "height, width, channel = img.shape\n",
    "# What size does the figure need to be in inches to fit the image?\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "# Create a figure of the right size with one axes that takes up the full figure\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.imshow(img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "for box in offsetarray:\n",
    "    #The bounding boxes are described as a ratio of the overall image dimensions, so we must multiply them\n",
    "    #by the total image dimensions to get the exact pixel values for each dimension.\n",
    "    x = box[0][0][0]\n",
    "    y = box[0][0][1]\n",
    "    width = box[0][1][0]-box[0][0][0]\n",
    "    height = box[0][3][1]-box[0][0][1]\n",
    "    rect = patches.Rectangle((x,y),width,height,linewidth=0,edgecolor=redacted_box_color,facecolor=redacted_box_color)\n",
    "    ax.add_patch(rect)\n",
    "#Ensure that no axis or whitespaces is printed in the image file we want to save.\n",
    "plt.axis('off')    \n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "#Save redacted image to the same Amazon S3 bucket, in PNG format, with 'de-id-' in front of the original filename.\n",
    "img_data = io.BytesIO()\n",
    "plt.savefig(img_data, bbox_inches='tight', pad_inches=0, format='png')\n",
    "img_data.seek(0)\n",
    "#Write the redacted image to S3\n",
    "img_bucket.put_object(Body=img_data, ContentType='image/png',  Key=\"redacted/\"+object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
